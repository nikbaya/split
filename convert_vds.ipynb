{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose which files to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"0\"     #already completed i = 0, 1, 2, 3, 4, 5 (available: 0,1,2,3,4,5,6)\n",
    "\n",
    "phen = '20160'\n",
    "desc = 'smoking'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gsutil', 'cp', 'gs://nbaya/split/20160_vdsA_s0.tsv.bgz', '/Users/nbaya/Documents/lab/ukbb-sexdiff/split/']\n",
      "['gsutil', 'cp', 'gs://nbaya/split/20160_vdsB_s0.tsv.bgz', '/Users/nbaya/Documents/lab/ukbb-sexdiff/split/']\n"
     ]
    }
   ],
   "source": [
    "for i in [\"A\",\"B\"]:\n",
    "    filename = phen+'_vds'+ i + '_s' + version\n",
    "    dlpath_cloud = 'gs://nbaya/split/'\n",
    "    path_local = '/Users/nbaya/Documents/lab/ukbb-sexdiff/split/'\n",
    "    subprocess.call(['gsutil','cp',dlpath_cloud + filename + '.tsv.bgz', path_local])\n",
    "\n",
    "    with gzip.open(path_local + filename + '.tsv.bgz', 'r') as f:\n",
    "        f.readline()\n",
    "        rows1 = []\n",
    "        rows2 = []\n",
    "        for line in f:\n",
    "            v, va = line.strip().split(b'\\t')\n",
    "            json_line2 = json.loads(va)\n",
    "            rows1.append(v.decode('utf-8'))\n",
    "            rows2.append(json_line2)\n",
    "\n",
    "    rsid = list(map(lambda x: x['rsid'], rows2))\n",
    "    A1 = list(map(lambda x: rows1[x].split(':')[3], range(len(rows1))))\n",
    "    A2 = list(map(lambda x: rows1[x].split(':')[2], range(len(rows1))))\n",
    "\n",
    "    df_linreg = pd.DataFrame(list(map(lambda x: (x['linreg']), rows2)))\n",
    "    N = df_linreg['nCompleteSamples']\n",
    "    Z = list(map(lambda x: x[0], df_linreg['tstat']))\n",
    "\n",
    "    df = pd.DataFrame({'SNP': rsid, 'A1': A1, 'A2': A2, 'N':N, 'Z': Z})\n",
    "\n",
    "    file_path_local = path_local + filename + '.tsv.gz'\n",
    "    df.to_csv(file_path_local, sep='\\t', compression='gzip', index=False)\n",
    "    path_cloud = 'gs://nbaya/split/test/'+filename+'.tsv.gz'\n",
    "    subprocess.call(['gsutil','cp',file_path_local, path_cloud])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update `{desc}.h2part.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2part_df = pd.read_csv(path_local+desc+'.h2part.tsv',delimiter='\\t')\n",
    "h2part_df.at[0,'female_file'] = phen+'_vdsA_s'+version+'.tsv.gz'\n",
    "h2part_df.at[0,'male_file'] = phen+'_vdsB_s'+version+'.tsv.gz'\n",
    "h2part_df.to_csv(path_local+desc+'.h2part.tsv',sep='\\t')\n",
    "subprocess.call(['gsutil','cp',path_local+desc+'.h2part.tsv','gs://nbaya/rg_sex/'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
